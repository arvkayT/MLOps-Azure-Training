{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de15745-5d1a-4746-918b-9812cd4af0d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- longitude: double (nullable = false)\n |-- latitude: double (nullable = false)\n |-- housing_median_age: double (nullable = false)\n |-- total_rooms: double (nullable = false)\n |-- total_bedrooms: double (nullable = false)\n |-- population: double (nullable = false)\n |-- households: double (nullable = false)\n |-- median_income: double (nullable = false)\n |-- median_house_value: double (nullable = false)\n |-- ocean_proximity: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_ROOT = pd.read_csv(\"Housing_preprocessed.csv\")\n",
    "\n",
    "#Print the dataframe schema\n",
    "housing.printSchema()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Filter for just numeric columns (and exclude median_house_value, our label)\n",
    "numericCols = [field for (field, dataType) in housing.dtypes if (((dataType == \"int\") or (dataType == \"double\")) & (field != \"median_house_value\"))]\n",
    "\n",
    "# Combine output of StringIndexer defined above and numeric columns\n",
    "#assemblerInputs = indexOutputCols + numericCols\n",
    "\n",
    "assemblerInputs = numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "#Split the data in train and test data\n",
    "(trainDF, testDF) = housing.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "rfw = RandomForestRegressor(labelCol=\"median_house_value\", featuresCol=\"features\", numTrees=10, seed=42)\n",
    "\n",
    "# Combine stages into pipeline\n",
    "stages = [vecAssembler, rfw]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Train model with Training Data\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "#Scoring the test data\n",
    "\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "308580fe-abd3-4b92-9a68-76ce3cd44c8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  modelpath = \"/dbfs/my_project_models/model-%f-%f\" % (alpha, l1_ratio)\n",
    "  mlflow.sklearn.save_model(lr, modelpath)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Model-Training",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
