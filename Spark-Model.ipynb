{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "207ad215-e44f-4802-9ebe-92d6be90911c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from six.moves import urllib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = DOWNLOAD_ROOT + os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f91c2f12-5249-4276-80de-36a3b39cc8eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a63829c-ef5c-417b-a153-61d05237ad60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30444937-6122-4078-a424-3558fb203f59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>longitude</th><th>latitude</th><th>housing_median_age</th><th>total_rooms</th><th>total_bedrooms</th><th>population</th><th>households</th><th>median_income</th><th>median_house_value</th><th>ocean_proximity</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0,
         0,
         0,
         0,
         0,
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "housing_median_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_rooms",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_bedrooms",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "population",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "households",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "median_income",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "median_house_value",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ocean_proximity",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "housing = spark.createDataFrame(housing)\n",
    "#Check for null values\n",
    "from pyspark.sql.functions import isnan, when, count, col,isnull\n",
    "\n",
    "housing = housing.na.fill(value=0)\n",
    "\n",
    "nullDF=housing.select([count(when(isnull(c), c)).alias(c) for c in housing.columns])\n",
    "\n",
    "display(nullDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2745dde6-bd92-41b5-a275-49e386fd1a3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: [('longitude', 'double'),\n ('latitude', 'double'),\n ('housing_median_age', 'double'),\n ('total_rooms', 'double'),\n ('total_bedrooms', 'double'),\n ('population', 'double'),\n ('households', 'double'),\n ('median_income', 'double'),\n ('median_house_value', 'double'),\n ('ocean_proximity', 'string')]"
     ]
    }
   ],
   "source": [
    "housing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de15745-5d1a-4746-918b-9812cd4af0d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- longitude: double (nullable = false)\n |-- latitude: double (nullable = false)\n |-- housing_median_age: double (nullable = false)\n |-- total_rooms: double (nullable = false)\n |-- total_bedrooms: double (nullable = false)\n |-- population: double (nullable = false)\n |-- households: double (nullable = false)\n |-- median_income: double (nullable = false)\n |-- median_house_value: double (nullable = false)\n |-- ocean_proximity: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Print the dataframe schema\n",
    "housing.printSchema()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Filter for just numeric columns (and exclude median_house_value, our label)\n",
    "numericCols = [field for (field, dataType) in housing.dtypes if (((dataType == \"int\") or (dataType == \"double\")) & (field != \"median_house_value\"))]\n",
    "\n",
    "# Combine output of StringIndexer defined above and numeric columns\n",
    "#assemblerInputs = indexOutputCols + numericCols\n",
    "\n",
    "assemblerInputs = numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "#Split the data in train and test data\n",
    "(trainDF, testDF) = housing.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "rfw = RandomForestRegressor(labelCol=\"median_house_value\", featuresCol=\"features\", numTrees=10, seed=42)\n",
    "\n",
    "# Combine stages into pipeline\n",
    "stages = [vecAssembler, rfw]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Train model with Training Data\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "#Scoring the test data\n",
    "\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8050799e-9d96-4d60-908b-ebf6e1b37a35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: 'd89020e170db445e9caf399eab9c634e'"
     ]
    }
   ],
   "source": [
    "# run_id = run.info.run_id\n",
    "# run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e19e3d2-7818-409a-b2c6-4021b1512268",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74048.90538268468\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/24 06:34:31 INFO mlflow.tracking.fluent: Experiment with name '/SparkML' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 74048.90538268468\nStage: Log Model Pipeline - Status: Started\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/24 06:34:43 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2023/05/24 06:36:46 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/2648146100547158/e18ed90be12e48db9fd562e9a76d58ff/artifacts/model/sparkml, flavor: spark), fall back to return ['pyspark==3.3.2', 'pandas<2']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: Log Model Pipeline - Status: Complete\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "eval_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = eval_rmse.evaluate(predDF)\n",
    "\n",
    "print(rmse)\n",
    "\n",
    "registry_uri=\"databricks://rmr:rmr\"\n",
    "\n",
    "# Use ML Flow to register the experiments in the local registry and register the trained model in the shared registry\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "mlflow.set_experiment(\"/SparkML\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"SparkML-Test\") as run:\n",
    "\n",
    "  # Log the algorithm parameter num_trees to the run\n",
    "  mlflow.log_param('num_trees', 10)\n",
    "\n",
    "\n",
    "  # Train model with Training Data\n",
    "  pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "  #Scoring the test data\n",
    "  predDF = pipelineModel.transform(testDF)\n",
    "  \n",
    "  #Evaluate the accuracy metrics\n",
    "  eval_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "  rmse = eval_rmse.evaluate(predDF)\n",
    "\n",
    "  print('RMSE is', str(rmse))\n",
    "  mlflow.log_param('rmse', rmse)\n",
    "  \n",
    "\n",
    "  # Log model\n",
    "  print(\"Stage: Log Model Pipeline - Status: Started\")\n",
    "  mlflow.spark.log_model(pipelineModel, \"model\")\n",
    "  print(\"Stage: Log Model Pipeline - Status: Complete\")\n",
    "\n",
    "  run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC \n",
    "# MAGIC Register the model in the shared registry\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "mlflow.set_registry_uri(registry_uri)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "#Register the mode with name: SparkModel\n",
    "# run_id = run.info.run_id\n",
    "# model_uri = f\"runs:/{run_id}/model\"\n",
    "# model_details = mlflow.register_model(model_uri=model_uri, name=\"SparkModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bb766a-404d-4c29-8605-8531a35e7e4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# artifact_path = \"model\"\n",
    "# model_uri = \"runs:/{run_id}/{artifact_path}\".format(run_id=run_id, artifact_path=artifact_path)\n",
    " \n",
    "# model_details = mlflow.register_model(model_uri=model_uri, name=\"SparkModel\")\n",
    "\n",
    "# # COMMAND ----------\n",
    "\n",
    "# #Set the status of the model to \"Staging\" as it's ready to be tested in the test environment\n",
    "\n",
    "\n",
    "# from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# client = MlflowClient()\n",
    "# model_version_details = client.get_model_version(name=\"SparkModel\", version=1)\n",
    "# model_version_details.status\n",
    "\n",
    "\n",
    "# # COMMAND ----------\n",
    "\n",
    "# client.transition_model_version_stage(\n",
    "#   name=model_details.name,\n",
    "#   version=model_details.version,\n",
    "#   stage=\"Staging\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44da68e4-37ee-4e61-8284-ed818c45d2a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark-Model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
